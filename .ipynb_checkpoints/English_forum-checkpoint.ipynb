{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English_forum\n",
    "\n",
    "Our project will be focus on obtain, treat and represent data from a web forum called “Englishforum”, in an automatized way. For that we will be using the tools learned during the lectures and other new ones. We can see an opportunity of getting interesant data and a direct aplication of data science.\n",
    "### Brief intro\n",
    "This web forum does the same paper than reddit but on Switterland. The website appeared around 2005 and has reach the number of 68,000 users, since then. With an average of 179,958 visits per day, this website has become an information exchange node.\n",
    "\n",
    "\n",
    "The first step of the project will be to obtain the data from the forum. Due to the quantity of data that we want to download, we need to implement an algorithm that goes through all the forum recollecting the data.\n",
    "Please notice that the function that we will implement is not simple and easily readable. Even if the forum has some fix template, this one varies in small details, making the need of adding particular cases on the way of treating forum pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4.element import Tag\n",
    "import pprint\n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a variable with the URL to this tutorial\n",
    "url = 'http://www.englishforum.ch/forum.php'\n",
    "# Scrape the HTML at the url\n",
    "r = requests.get(url)\n",
    "# Turn the HTML into a Beautiful Soup object\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"3\">We will start collecting al the topics of the forum:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business & entrepreneur': 'http://www.englishforum.ch/business-entrepreneur/',\n",
       " 'Commercial events': 'http://www.englishforum.ch/commercial-events/',\n",
       " 'Complaints corner': 'http://www.englishforum.ch/complaints-corner/',\n",
       " 'Concerts': 'http://www.englishforum.ch/concerts/',\n",
       " 'Daily life': 'http://www.englishforum.ch/daily-life/',\n",
       " 'Education': 'http://www.englishforum.ch/education/',\n",
       " 'Employment': 'http://www.englishforum.ch/employment/',\n",
       " 'Entertainment & dining': 'http://www.englishforum.ch/entertainment-dining/',\n",
       " 'Family matters/health': 'http://www.englishforum.ch/family-matters-health/',\n",
       " 'Finance/banking/taxation': 'http://www.englishforum.ch/finance-banking-taxation/',\n",
       " 'Food and drink': 'http://www.englishforum.ch/food-drink/',\n",
       " 'Housing in general': 'http://www.englishforum.ch/housing-general/',\n",
       " 'Insurance': 'http://www.englishforum.ch/insurance/',\n",
       " 'Introductions': 'http://www.englishforum.ch/introductions/',\n",
       " 'Language corner': 'http://www.englishforum.ch/language-corner/',\n",
       " 'Leaving Switzerland': 'http://www.englishforum.ch/leaving-switzerland/',\n",
       " 'Market Place': 'http://www.englishforum.ch/market-place/',\n",
       " 'Off-Topic': 'http://www.englishforum.ch/off-topic/',\n",
       " 'Other/general': 'http://www.englishforum.ch/other-general/',\n",
       " 'Permits/visas/government': 'http://www.englishforum.ch/permits-visas-government/',\n",
       " 'Pet corner': 'http://www.englishforum.ch/pet-corner/',\n",
       " 'Social events': 'http://www.englishforum.ch/social-events/',\n",
       " 'Sports / Fitness / Beauty / Wellness': 'http://www.englishforum.ch/sports-fitness-beauty-wellness/',\n",
       " 'Support': 'http://www.englishforum.ch/support/',\n",
       " 'Swiss news via The Local': 'http://www.englishforum.ch/swiss-news-via-local/',\n",
       " 'Swiss politics/news': 'http://www.englishforum.ch/swiss-politics-news/',\n",
       " 'TV/internet/telephone': 'http://www.englishforum.ch/tv-internet-telephone/',\n",
       " 'Transportation/driving': 'http://www.englishforum.ch/transportation-driving/',\n",
       " 'Travel/day trips/free time': 'http://www.englishforum.ch/travel-day-trips-free-time/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create four variables to score the scraped data in\n",
    "dataframes={}\n",
    "for link in soup.find_all(\"strong\")[1:]:\n",
    "    for linkhref in soup.find_all(\"a\"):\n",
    "        if(link in linkhref and not linkhref['href'].endswith('.html') and link.contents[0] not in dataframes):\n",
    "            dataframes[link.contents[0]]=linkhref['href']\n",
    "dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch the info from urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell contains several functions that download the data from each topic of the forum and store it on a dataframe.\n",
    "\n",
    "The data that we decide to collect from each topic is:\n",
    "\n",
    "    -Thread: Name of the thread.\n",
    "    -User: Creator of the thread.\n",
    "    -Views: Number of views of that thread\n",
    "    -Replies: Number of replies in that thread\n",
    "    -Location: Location of the user\n",
    "    -Date: Date of creation of the thread\n",
    "    -Posts: All posts of each thread\n",
    "    -User_posts:\n",
    "    -Since: Date of registration of the user\n",
    "    -Exp: Level of experience of the user.\n",
    "    -Thanked: Number of times been thanked of each user\n",
    "    -Groaned: Number of times been groaned of each user\n",
    "    -Reputation: Level of reputation of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comments(numPag,thread):\n",
    "    # Scrape the HTML at the url\n",
    "    response = requests.get(thread,headers={'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'})\n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    comments={}\n",
    "    inception={}\n",
    "    date=''\n",
    "    first=[]\n",
    "    user_and_rep=[]\n",
    "    for link in soup.find_all(\"div\",{\"align\":\"center\"}):\n",
    "        for link2 in link.find_all(\"div\",{\"align\":\"left\"}):\n",
    "            for link3 in link2.find_all(\"tr\"):\n",
    "                for link4 in link3.find_all(\"td\",{\"width\":\"99%\"}):\n",
    "                    for link5 in link4.find_all(\"div\"):\n",
    "                        if('id' in link5.attrs and 'posts' in link5['id']):\n",
    "                            link6=link5.find('table')\n",
    "\n",
    "                            try:\n",
    "                                link7=link6.find('td').find_all('div')\n",
    "                                if(len(link7)==0):\n",
    "                                    date='null'\n",
    "                                else:\n",
    "                                    date=link7[-1].contents[-1].strip(' \\n\\r\\t')\n",
    "                            except IndexError as  err:\n",
    "                                print(link6)\n",
    "                                print(thread)\n",
    "                                logging.error(traceback.format_exc())\n",
    "                                \n",
    "                            if(numPag==0 and 'null' not in date):\n",
    "                                for ind,link7 in enumerate(link6.find_all('div')):\n",
    "                                    if('href' not in link7 and len(link7.contents)>0):\n",
    "                                        if(type(link7.contents[0])==Tag):\n",
    "                                            if(len(link7.attrs)==0):\n",
    "                                                    user_and_rep=str(link7.contents[0]).partition('alt=')[2]\n",
    "                                                    user_and_rep=user_and_rep.partition(user_and_rep[0]+' border')[0]\n",
    "                                                    if('has' in user_and_rep):\n",
    "                                                        user_and_rep=user_and_rep.partition(' has ')\n",
    "                                                    elif('is' in user_and_rep):\n",
    "                                                        user_and_rep=user_and_rep.partition(' is ')\n",
    "                                                    user_and_rep=[user_and_rep[0],user_and_rep[2]]\n",
    "                                               \n",
    "                                        else:\n",
    "                                            stat=link7.contents[0].strip('\\n\\r\\t')\n",
    "                                            if(len(stat)>1 and ord(stat[0])!=160):\n",
    "                                                first.append(stat)\n",
    "                        if('id' in link5.attrs and link5['id'].startswith('post_message')):\n",
    "                            contents=''\n",
    "                            for content in link5.contents:\n",
    "                                if type(content) is not Tag:\n",
    "                                    contents+=' '+content\n",
    "                                elif(str(content).startswith('<font')):\n",
    "                                    contents+=' '+re.sub(r'<.*?>', '', str(content))\n",
    "                                \n",
    "                            comments[link5['id']]=contents\n",
    "    retcomments=''\n",
    "    for ind,i in enumerate(sorted(comments)):\n",
    "        if(numPag==0):\n",
    "            if(len(first)==6):\n",
    "                first.append(comments[i])\n",
    "            else:\n",
    "                first[-1]=comments[i]\n",
    "        retcomments+=comments[i]\n",
    "\n",
    "        try:\n",
    "            if(numPag==0 and len(first)==7 and 'null' not in date):\n",
    "                inception['user']=user_and_rep[0][1:]\n",
    "                inception['date']=date\n",
    "                inception['reputation']=user_and_rep[1]\n",
    "                inception['exp']=first[0]\n",
    "                inception['since']=first[1]\n",
    "                inception['location']=first[2]\n",
    "                inception['posts']=first[3]\n",
    "                inception['groaned']=first[4]\n",
    "                inception['thanked']=first[5]\n",
    "                inception['post']=first[6]\n",
    "            elif(numPag==0):\n",
    "                inception['user']='guest'\n",
    "                inception['date']='null'\n",
    "                inception['reputation']='null'\n",
    "                inception['exp']='null'\n",
    "                inception['since']='null'\n",
    "                inception['location']='null'\n",
    "                inception['posts']='null'\n",
    "                inception['thanked']='null'\n",
    "                inception['groaned']='null'\n",
    "                inception['post']=first[-1]\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            print(thread)\n",
    "            if(numPag==0):\n",
    "                inception['user']='guest'\n",
    "                inception['date']='null'\n",
    "                inception['reputation']='null'\n",
    "                inception['exp']='null'\n",
    "                inception['since']='null'\n",
    "                inception['location']='null'\n",
    "                inception['posts']='null'\n",
    "                inception['thanked']='null'\n",
    "                inception['groaned']='null'\n",
    "                inception['post']=first[-1]\n",
    "\n",
    "    return [retcomments,inception]\n",
    "\n",
    "def page(url,index):\n",
    "\n",
    "    # Scrape the HTML at the url\n",
    "    r = requests.get(url)    \n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    subtopic={}\n",
    "    for link in soup.find_all(\"table\",id=\"threadslist\"):\n",
    "        index_aux=index\n",
    "        dash=0\n",
    "        for replies in link.find_all(\"td\",class_=\"alt1\"):\n",
    "            if(replies.contents[0]!=' ' and type(replies.contents[0])!=Tag):\n",
    "                if(replies.contents[0]=='-'):\n",
    "                    dash+=1\n",
    "                subtopic[index_aux]=[]\n",
    "                subtopic[index_aux].append(replies.contents[0])\n",
    "                index_aux+=1\n",
    "\n",
    "        index_aux=index\n",
    "        insertdash=0\n",
    "        # \\xa0 Unicode --> ascii 160\n",
    "        for views in link.find_all(\"td\",class_=\"alt2\"):\n",
    "            if('align' in views.attrs and views.contents[0]!=' ' and ord(views.contents[0][0])!=160 and type(views.contents[0])!=Tag):\n",
    "                if(views.contents[0]=='-'):\n",
    "                    if(insertdash==0):\n",
    "                        insertdash=1\n",
    "                    else:\n",
    "                        insertdash=0\n",
    "                        subtopic[index_aux].append(views.contents[0])\n",
    "                        index_aux+=1\n",
    "                else:\n",
    "                    subtopic[index_aux].append(views.contents[0])\n",
    "                    index_aux+=1    \n",
    "        for thread in link.find_all(\"a\"):\n",
    "            if('id' in thread.attrs):\n",
    "                    subtopic[index].append(thread['href'])\n",
    "                    subtopic[index].append(thread.contents[0])\n",
    "                    index+=1\n",
    "        \n",
    "    return [subtopic,index]\n",
    "    \n",
    "    \n",
    "def findAllPages(rootHTML):\n",
    "    # Scrape the HTML at the url\n",
    "    r = requests.get(rootHTML)    \n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    lastUrl=''\n",
    "    pages=[]\n",
    "    pages.append(rootHTML)\n",
    "    for link in soup.find_all(\"body\"):\n",
    "        for link1 in link.find_all(\"a\"):\n",
    "            if('title' in link1.attrs and 'Last' in link1['title']):\n",
    "                lastUrl=link1['href']\n",
    "                break\n",
    "    if(lastUrl==''):#no Last page link, we fetch last index page\n",
    "        links=set()\n",
    "        for link in soup.find_all(\"body\"):\n",
    "            for link1 in link.find_all(\"a\"):\n",
    "                if('title' in link1.attrs and 'Show results' in link1['title']):\n",
    "                    links.add(link1['href'])\n",
    "#                     print(link1)\n",
    "        if(links!=set() and rootHTML!=sorted(links)[-1]):\n",
    "            lastUrl=sorted(links)[-1]\n",
    "    if(lastUrl!=''):\n",
    "        if(rootHTML.endswith('.html')):\n",
    "            limit=re.findall(r'\\d+',lastUrl)[-1]\n",
    "            for i in range(2,int(limit)):\n",
    "                pages.append(re.sub(r'.html','',rootHTML)+\"-\"+str(i)+\".html\")\n",
    "        else:\n",
    "            limit=re.findall(r'\\d+',lastUrl)[0]\n",
    "            for i in range(2,int(limit)):\n",
    "                pages.append(rootHTML+\"index\"+str(i)+\".html\")\n",
    "        pages.append(lastUrl)\n",
    "        return pages\n",
    "    return pages\n",
    "    \n",
    "def createDF(url):\n",
    "    index=0\n",
    "    allsubtopics={}\n",
    "    nextPages=findAllPages(url)\n",
    "    for url in nextPages:\n",
    "        result=page(url,index)\n",
    "        allsubtopics.update(result[0])\n",
    "        index=result[1]\n",
    "    replies=[]\n",
    "    views=[]\n",
    "    hrefs=[]\n",
    "    threads=[]\n",
    "    first_posts=[]\n",
    "    print(\"For this tipic: %s there are %d subtopics\" %(url,len(allsubtopics)))\n",
    "    for value in allsubtopics.values():\n",
    "        replies.append(value[0])\n",
    "        views.append(value[1])\n",
    "        hrefs.append(value[2])\n",
    "        threads.append(value[3])\n",
    "    posts=[]\n",
    "    porcentaje=0\n",
    "    for indexhref,href in enumerate(hrefs):\n",
    "        nextPages=findAllPages(href)\n",
    "        threadPosts=[]\n",
    "        for numPag,pag in enumerate(nextPages):\n",
    "\n",
    "            comments_call=comments(numPag,pag)\n",
    "            threadPosts.append(comments_call[0])\n",
    "            if(numPag==0):\n",
    "                first_posts.append(comments_call[1])\n",
    "        posts.append(''.join(threadPosts))\n",
    "        if((((indexhref*100)/len(hrefs)))>porcentaje):\n",
    "            print('Percentage of thread: ',int((indexhref*100)/len(hrefs)))\n",
    "            porcentaje=porcentaje+20;\n",
    "    date=[]\n",
    "    exp=[]\n",
    "    groaned=[]\n",
    "    location=[]\n",
    "    post=[]\n",
    "    user_posts=[]\n",
    "    reputation=[]\n",
    "    since=[]\n",
    "    thanked=[]\n",
    "    user=[]\n",
    "#     example of element first_posts\n",
    "#   {'date': '19.12.2014',\n",
    "#   'exp': 'Newbie',\n",
    "#   'groaned': 'Thanked 0 Times in 0 Posts',\n",
    "#   'location': 'Location: Basel',\n",
    "#   'post': \"Hi all. new to this site, i've been in basel for about 6 months now and was wondering about where and how i can buy e-cigarettes. i've heard they help people quit smoking and i read they are much cheaper too.\",\n",
    "#   'posts': 'Posts: 6',\n",
    "#   'reputation': 'has made some interesting contributions',\n",
    "#   'since': 'Join Date: Dec 2014',\n",
    "#   'thanked': 'Groaned at 1 Time in 1 Post',\n",
    "#   'user': 'WisePotato'}]\n",
    "    for index,stat in enumerate(first_posts):\n",
    "        if(len(stat)<9):\n",
    "            date.append('null')\n",
    "            exp.append('null')\n",
    "            groaned.append('null')\n",
    "            location.append('null')\n",
    "            post.append('null')\n",
    "            user_posts.append('null')\n",
    "            reputation.append('null')\n",
    "            since.append('null')\n",
    "            thanked.append('null')\n",
    "            user.append('null')\n",
    "        else:\n",
    "            date.append(stat['date'])\n",
    "            exp.append(stat['exp'])\n",
    "            groaned.append(stat['groaned'])\n",
    "            location.append(stat['location'])\n",
    "            post.append(stat['post'])\n",
    "            user_posts.append(stat['posts'])\n",
    "            reputation.append(stat['reputation'])\n",
    "            since.append(stat['since'])\n",
    "            thanked.append(stat['thanked'])\n",
    "            user.append(stat['user'])\n",
    "    joindf=pd.DataFrame({'thread':threads,'user':user,'views': views,'replies': replies,'location':location,'date':date,'post':posts,'user_posts':user_posts,'since':since,'exp':exp,'thanked':thanked,'groaned':groaned,'reputation':reputation})\n",
    "    return joindf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data into csv folder and remove dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function will allowq us to save the dataframes into csv. We will do it after a general parse of the downloaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveData(dataframe,i):\n",
    "    dataframe.to_csv(\"csv/\"+i.replace(\"/\",\"\")+\".csv\", sep='\\t', encoding='utf-8',)\n",
    "    del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes we'd like to fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Business & entrepreneur http://www.englishforum.ch/business-entrepreneur/\n",
      "1 Commercial events http://www.englishforum.ch/commercial-events/\n",
      "2 Complaints corner http://www.englishforum.ch/complaints-corner/\n",
      "3 Concerts http://www.englishforum.ch/concerts/\n",
      "4 Daily life http://www.englishforum.ch/daily-life/\n",
      "5 Education http://www.englishforum.ch/education/\n",
      "6 Employment http://www.englishforum.ch/employment/\n",
      "7 Entertainment & dining http://www.englishforum.ch/entertainment-dining/\n",
      "8 Family matters/health http://www.englishforum.ch/family-matters-health/\n",
      "9 Finance/banking/taxation http://www.englishforum.ch/finance-banking-taxation/\n",
      "10 Food and drink http://www.englishforum.ch/food-drink/\n",
      "11 Housing in general http://www.englishforum.ch/housing-general/\n",
      "12 Insurance http://www.englishforum.ch/insurance/\n",
      "13 Introductions http://www.englishforum.ch/introductions/\n",
      "14 Language corner http://www.englishforum.ch/language-corner/\n",
      "15 Leaving Switzerland http://www.englishforum.ch/leaving-switzerland/\n",
      "16 Market Place http://www.englishforum.ch/market-place/\n",
      "17 Off-Topic http://www.englishforum.ch/off-topic/\n",
      "18 Other/general http://www.englishforum.ch/other-general/\n",
      "19 Permits/visas/government http://www.englishforum.ch/permits-visas-government/\n",
      "20 Pet corner http://www.englishforum.ch/pet-corner/\n",
      "21 Social events http://www.englishforum.ch/social-events/\n",
      "22 Sports / Fitness / Beauty / Wellness http://www.englishforum.ch/sports-fitness-beauty-wellness/\n",
      "23 Support http://www.englishforum.ch/support/\n",
      "24 Swiss news via The Local http://www.englishforum.ch/swiss-news-via-local/\n",
      "25 Swiss politics/news http://www.englishforum.ch/swiss-politics-news/\n",
      "26 TV/internet/telephone http://www.englishforum.ch/tv-internet-telephone/\n",
      "27 Transportation/driving http://www.englishforum.ch/transportation-driving/\n",
      "28 Travel/day trips/free time http://www.englishforum.ch/travel-day-trips-free-time/\n"
     ]
    }
   ],
   "source": [
    "# for i in dataframes:\n",
    "for index,i in enumerate(sorted(dataframes)):\n",
    "    print(index,i,dataframes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In case we'd like to update the files, let's declare the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_enterpreteur=None\n",
    "complaints_corner=None\n",
    "concerts=None\n",
    "daily_life=None\n",
    "employment=None\n",
    "entertainment_dining=None\n",
    "family_matters_health=None\n",
    "finance_banking_taxation=None\n",
    "food_drink=None\n",
    "housing=None\n",
    "insurance=None\n",
    "introductions=None\n",
    "language_corner=None\n",
    "leaving_switzerland=None\n",
    "market_place=None\n",
    "off_topic=None\n",
    "other_general=None\n",
    "permits_visas_gov=None\n",
    "pet_corner=None\n",
    "sports_wellness=None\n",
    "support=None\n",
    "swiss_politics_news=None\n",
    "transportation_driving=None\n",
    "travel_free_time=None\n",
    "tv_internet_telephone=None\n",
    "# NON FETCHED BUT YET TO COME\n",
    "commercial_events=None\n",
    "education=None\n",
    "social_events=None\n",
    "swiss_news=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's download them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the data from the forum can take around 1-2 days and some times we just want to update part of the data. \n",
    "The cell below allow us to choose which topics (of the forum) we would like to download. \n",
    "By commenting lines you will select he topics you want to download.\n",
    "If you want to guive a try, concerts is a good example because of it short length (meaning with short, the quantity of threads/post inside it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 http://www.englishforum.ch/business-entrepreneur/\n",
      "1 http://www.englishforum.ch/commercial-events/\n",
      "2 http://www.englishforum.ch/complaints-corner/\n",
      "3 http://www.englishforum.ch/concerts/\n",
      "For this tipic: http://www.englishforum.ch/concerts/index29.html there are 848 subtopics\n",
      "Percentage of thread:  0\n",
      "Percentage of thread:  20\n",
      "Percentage of thread:  40\n",
      "Percentage of thread:  60\n",
      "Percentage of thread:  80\n",
      "4 http://www.englishforum.ch/daily-life/\n",
      "5 http://www.englishforum.ch/education/\n",
      "6 http://www.englishforum.ch/employment/\n",
      "7 http://www.englishforum.ch/entertainment-dining/\n",
      "8 http://www.englishforum.ch/family-matters-health/\n",
      "9 http://www.englishforum.ch/finance-banking-taxation/\n",
      "10 http://www.englishforum.ch/food-drink/\n",
      "11 http://www.englishforum.ch/housing-general/\n",
      "12 http://www.englishforum.ch/insurance/\n",
      "13 http://www.englishforum.ch/introductions/\n",
      "14 http://www.englishforum.ch/language-corner/\n",
      "15 http://www.englishforum.ch/leaving-switzerland/\n",
      "16 http://www.englishforum.ch/market-place/\n",
      "17 http://www.englishforum.ch/off-topic/\n",
      "18 http://www.englishforum.ch/other-general/\n",
      "19 http://www.englishforum.ch/permits-visas-government/\n",
      "20 http://www.englishforum.ch/pet-corner/\n",
      "21 http://www.englishforum.ch/social-events/\n",
      "22 http://www.englishforum.ch/sports-fitness-beauty-wellness/\n",
      "23 http://www.englishforum.ch/support/\n",
      "24 http://www.englishforum.ch/swiss-news-via-local/\n",
      "25 http://www.englishforum.ch/swiss-politics-news/\n",
      "26 http://www.englishforum.ch/tv-internet-telephone/\n",
      "27 http://www.englishforum.ch/transportation-driving/\n",
      "28 http://www.englishforum.ch/travel-day-trips-free-time/\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(sorted(dataframes)):\n",
    "    print(index, dataframes[i])\n",
    "#     df=createDF(dataframes[i][0])\n",
    "#     saveData(df)\n",
    "    if index==0: skip=1          #  business_enterpreteur\n",
    "    elif index==1: skip=1        #  commercial-events\n",
    "    elif index==2: skip=1        #  complaints-corner\n",
    "#     elif index==3: skip=1        #  concerts \n",
    "    elif index==4: skip=1        #  daily-life\n",
    "    elif index==5: skip=1        #  education\n",
    "    elif index==6: skip=1        #  employment\n",
    "    elif index==7: skip=1        #  entertainment-dining\n",
    "    elif index==8: skip=1        #  family-matters-health\n",
    "    elif index==9: skip=1        #  finance-banking-taxation\n",
    "    elif index==10: skip=1       #  food-drink\n",
    "    elif index==11: skip=0       #  housing-general/\n",
    "    elif index==12: skip=1       #  insurance\n",
    "    elif index==13: skip=1       #  introductions\n",
    "    elif index==14: skip=1       #  language_corner\n",
    "    elif index==15: skip=1       #  leaving_switzerland\n",
    "    elif index==16: skip=0       #  market_place\n",
    "    elif index==17: skip=0       #  off_topic\n",
    "    elif index==18: skip=1       #  other_general\n",
    "    elif index==19: skip=1       #  permits_visas_gov\n",
    "    elif index==20: skip=1       #  pet_corner\n",
    "    elif index==21: skip=1       #  social_events\n",
    "    elif index==22: skip=1       #  sports_wellness\n",
    "    elif index==23: skip=0       #  support\n",
    "    elif index==24: skip=1       #  swiss_news\n",
    "    elif index==25: skip=1       #  swiss_politics_news\n",
    "    elif index==26: skip=1       #  tv_internet_telephone\n",
    "    elif index==27: skip=1       #  transportation_driving\n",
    "    elif index==28: skip=1\n",
    "    else:     \n",
    "        try:\n",
    "            createDFRet=createDF(dataframes[i])\n",
    "            createDFRet['topic']=i\n",
    "            saveData(createDFRet,(i+\"Authors\"))\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to read from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    if( not filename.endswith('.csv')):\n",
    "        filename+='.csv'\n",
    "    df = pd.read_csv('csv/'+filename, header=0,sep='\\t',index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV files we have got so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Business & entrepreneur.csv\n",
      "1 Business & entrepreneurAuthors.csv\n",
      "2 Commercial events.csv\n",
      "3 Commercial eventsAuthors.csv\n",
      "4 Complaints corner.csv\n",
      "5 Complaints cornerAuthors.csv\n",
      "6 Concerts.csv\n",
      "7 ConcertsAuthors.csv\n",
      "8 Daily life.csv\n",
      "9 Daily lifeAuthors.csv\n",
      "10 Education.csv\n",
      "11 EducationAuthors.csv\n",
      "12 Employment.csv\n",
      "13 EmploymentAuthors.csv\n",
      "14 Entertainment & dining.csv\n",
      "15 Entertainment & diningAuthors.csv\n",
      "16 Family mattershealth.csv\n",
      "17 Family mattershealthAuthors.csv\n",
      "18 Financebankingtaxation.csv\n",
      "19 FinancebankingtaxationAuthors.csv\n",
      "20 Food and drink.csv\n",
      "21 Food and drinkAuthors.csv\n",
      "22 Insurance.csv\n",
      "23 InsuranceAuthors.csv\n",
      "24 Introductions.csv\n",
      "25 IntroductionsAuthors.csv\n",
      "26 Language corner.csv\n",
      "27 Language cornerAuthors.csv\n",
      "28 Leaving Switzerland.csv\n",
      "29 Leaving SwitzerlandAuthors.csv\n",
      "30 Othergeneral.csv\n",
      "31 OthergeneralAuthors.csv\n",
      "32 Permitsvisasgovernment.csv\n",
      "33 PermitsvisasgovernmentAuthors.csv\n",
      "34 Pet corner.csv\n",
      "35 Pet cornerAuthors.csv\n",
      "36 Social events.csv\n",
      "37 Social eventsAuthors.csv\n",
      "38 Sports  Fitness  Beauty  Wellness.csv\n",
      "39 Sports  Fitness  Beauty  WellnessAuthors.csv\n",
      "40 Swiss news via The Local.csv\n",
      "41 Swiss news via The LocalAuthors.csv\n",
      "42 Swiss politicsnews.csv\n",
      "43 Swiss politicsnewsAuthors.csv\n",
      "44 TVinternettelephone.csv\n",
      "45 TVinternettelephoneAuthors.csv\n",
      "46 Transportationdriving.csv\n",
      "47 TransportationdrivingAuthors.csv\n",
      "48 Travelday tripsfree time.csv\n",
      "49 Travelday tripsfree timeAuthors.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for index,i in enumerate(sorted(os.listdir(\"csv/\"))):\n",
    "    print(index,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data at once, parse it and save it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded our data and save it to localstorage, we need to be transform it from ”dirty” to clean, as we saw during the course.\n",
    "We will remove some incoherent information, treat null and parse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['csv/ConcertsAuthors.csv'] dict_keys(['ConcertsAuthors'])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "dfAuthors={}\n",
    "filenames = [fn for fn in glob.glob(\"csv/*.csv\") \n",
    "         if os.path.basename(fn).endswith('Authors.csv')]\n",
    "for index,filename in enumerate(filenames):\n",
    "    df = pd.read_csv(filename, header=0,sep='\\t',index_col=0)\n",
    "    dfAuthors[re.sub(r'.csv','',os.path.basename(filename))]=df\n",
    "print(filenames,dfAuthors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our data initially looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>Groaned at 1 Time in 1 Post</td>\n",
       "      <td>Location: Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1,100</td>\n",
       "      <td>a reputation beyond repute</td>\n",
       "      <td>Join Date: Mar 2006</td>\n",
       "      <td>Thanked 901 Times in 444 Posts</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>Posts: 1,233</td>\n",
       "      <td>152,605</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>Groaned at 0 Times in 0 Posts</td>\n",
       "      <td>Location: Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Join Date: Nov 2016</td>\n",
       "      <td>Thanked 0 Times in 0 Posts</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>Posts: 3</td>\n",
       "      <td>978</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.11.2015, 22:48</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>Groaned at 0 Times in 0 Posts</td>\n",
       "      <td>Location: Spain</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tHello there!   \\r\\nI am a...</td>\n",
       "      <td>16</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Join Date: Jul 2015</td>\n",
       "      <td>Thanked 0 Times in 0 Posts</td>\n",
       "      <td>Jazz clubs Zurich?</td>\n",
       "      <td>aromeroa</td>\n",
       "      <td>Posts: 6</td>\n",
       "      <td>3,869</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp                        groaned  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran    Groaned at 1 Time in 1 Post   \n",
       "1  19.11.2016, 19:45         Newbie  Groaned at 0 Times in 0 Posts   \n",
       "2  28.11.2015, 22:48         Newbie  Groaned at 0 Times in 0 Posts   \n",
       "\n",
       "                     location  \\\n",
       "0           Location: Perthia   \n",
       "1  Location: Lenzburg, Aargau   \n",
       "2             Location: Spain   \n",
       "\n",
       "                                                post replies  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...   1,100   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5   \n",
       "2   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tHello there!   \\r\\nI am a...      16   \n",
       "\n",
       "                            reputation                since  \\\n",
       "0           a reputation beyond repute  Join Date: Mar 2006   \n",
       "1  no particular reputation at present  Join Date: Nov 2016   \n",
       "2  no particular reputation at present  Join Date: Jul 2015   \n",
       "\n",
       "                          thanked                                      thread  \\\n",
       "0  Thanked 901 Times in 444 Posts                 Switzerland Gigs \"Heads Up\"   \n",
       "1      Thanked 0 Times in 0 Posts  Small bars/places with acoustic livemusic?   \n",
       "2      Thanked 0 Times in 0 Posts                          Jazz clubs Zurich?   \n",
       "\n",
       "       user    user_posts    views     topic  \n",
       "0    Yokine  Posts: 1,233  152,605  Concerts  \n",
       "1       JHC      Posts: 3      978  Concerts  \n",
       "2  aromeroa      Posts: 6    3,869  Concerts  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuthors['ConcertsAuthors'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parsing\n",
    "All cells are string type. We would like to convert all string numbers to integers (or floats) and for that we need to remove the comas.\n",
    "We also want to transform dates represented in the same way (column \"date\" can have date types and text as \"today\" or \"yesterday\")\n",
    "Finally, there is useless text mixed with more important data like in the column \"location\", in which we can find the word \"location:\" always repeted per cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>a reputation beyond repute</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>152605</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>978</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45         Newbie  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5   \n",
       "\n",
       "                            reputation      since     thanked  \\\n",
       "0           a reputation beyond repute   Mar 2006  [901, 444]   \n",
       "1  no particular reputation at present   Nov 2016      [0, 0]   \n",
       "\n",
       "                                       thread    user user_posts   views  \\\n",
       "0                 Switzerland Gigs \"Heads Up\"  Yokine       1233  152605   \n",
       "1  Small bars/places with acoustic livemusic?     JHC          3     978   \n",
       "\n",
       "      topic  \n",
       "0  Concerts  \n",
       "1  Concerts  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "for key in dfAuthors:\n",
    "    # # Casting views from str to int (- to 0 because is a moved)\n",
    "    today=datetime.strptime(time.ctime(os.path.getctime('csv/'+key+'.csv')),'%a %b %d %H:%M:%S %Y')\n",
    "    yesterday=today- timedelta(days=1)\n",
    "    tdy=\"%d.%d.%d\" %(today.day,today.month,today.year)\n",
    "    ystr=\"%d.%d.%d\" %(yesterday.day,yesterday.month,yesterday.year)\n",
    "    \n",
    "    dfAuthors[key]['views']=dfAuthors[key]['views'].apply(lambda x: str(x).replace(',',''))\n",
    "    dfAuthors[key]['replies']=dfAuthors[key]['replies'].apply(lambda x: str(x).replace(',',''))\n",
    "    dfAuthors[key]['user_posts']=dfAuthors[key]['user_posts'].apply(lambda x: ''.join(re.findall(r'\\d+',x)))\n",
    "    dfAuthors[key]['user']=dfAuthors[key]['user'].apply(lambda x: str(x).replace(str(x)[0],'') if((str(x)[0])=='\"') else str(x))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: str(x))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: x.replace('Yesterday',ystr))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: x.replace('Today',tdy))\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: str(x))\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: x.replace('Join Date:',''))\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: x.replace('null',(\" Jun 0001\")))\n",
    "    dfAuthors[key]['location']=dfAuthors[key]['location'].apply(lambda x: x.replace('Location: ',''))\n",
    "#     Thanked 418 Times in 115 \n",
    "#     Groaned at 3 Times in 3 Posts\n",
    "    dfAuthors[key]['groaned']=dfAuthors[key]['groaned'].apply(lambda x: re.findall(r'\\d+',x))\n",
    "    dfAuthors[key]['thanked']=dfAuthors[key]['thanked'].apply(lambda x: re.findall(r'\\d+',x))\n",
    "dfAuthors[key].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reputation transformation.\n",
    "We have easily identify the genaeral reputation of the memebers and give them a numeric value that goes from -5 to 6. However, some users have strange values, probably due to a wrong download or in some cases a glitch of the forum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reputation values:  ['a reputation beyond repute' 'no particular reputation at present'\n",
      " 'slipped a little' 'considered knowledgeable'\n",
      " 'made some interesting contributions' 'earned some respect' 'null'\n",
      " 'become a little unpopular' 'an excellent reputation'\n",
      " 'considered a nuisance' 'annoyed a few people around here'\n",
      " 'earned the respect of many' 'm' 'considered unworthy']\n"
     ]
    }
   ],
   "source": [
    "print('Reputation values: ',dfAuthors['ConcertsAuthors']['reputation'].unique())\n",
    "d = {}\n",
    "d[\"a reputation beyond repute\"] = 6 # \n",
    "d[\"an excellent reputation\"] = 5 # \n",
    "d[\"considered knowledgeable\"] = 4 #\n",
    "d[\"earned the respect of many\"] = 3 #\n",
    "d[\"earned some respect\"] = 2#\n",
    "d[\"made some interesting contributions\"] = 1 #\n",
    "d[\"no particular reputation at present\"] = 0#1\n",
    "d[\"slipped a little\"] = -1 #0\n",
    "d[\"become a little unpopular\"] = -2 #\n",
    "d[\"annoyed a few people around here\"] = -3 #\n",
    "d[\"considered a nuisance\"] = -4 #\n",
    "d[\"considered unworthy\"] = -5 #\n",
    "d[\"null\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unparse values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m', nan, 'u', 'h', 'a'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques=set()\n",
    "[[uniques.add(user_exp) for user_exp in dfAuthors[key]['reputation'] if user_exp not in list(d.keys())]for key in dfAuthors]\n",
    "uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe after the reputation parse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>6</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>152605</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>978</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45         Newbie  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies reputation  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100          6   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5          0   \n",
       "\n",
       "       since     thanked                                      thread    user  \\\n",
       "0   Mar 2006  [901, 444]                 Switzerland Gigs \"Heads Up\"  Yokine   \n",
       "1   Nov 2016      [0, 0]  Small bars/places with acoustic livemusic?     JHC   \n",
       "\n",
       "  user_posts   views     topic  \n",
       "0       1233  152605  Concerts  \n",
       "1          3     978  Concerts  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dfAuthors:\n",
    "    dfAuthors[key]['reputation']=[d.get(item,item)  for item in dfAuthors[key]['reputation']]\n",
    "dfAuthors[key].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experience transformation.\n",
    "We have easily identify the genaeral experience of the memebers and give them a numeric value too. It goes from -1 to 7. In this case, there are special members that have unique rolls. We can also consider the exp values as a kind of rol for especial users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp values:  ['Forum Veteran' 'Newbie' 'Forum Legend' 'Junior Member' 'Member'\n",
      " 'Newbie 1st class' 'Senior Member' 'null' 'Banned'\n",
      " 'modified and reprogrammed' 'RIP' 'Moderato espressivo']\n"
     ]
    }
   ],
   "source": [
    "print('Exp values: ',dfAuthors[key]['exp'].unique())\n",
    "# Basic exp\n",
    "d = {}\n",
    "d[\"Newbie\"] = 0 # \n",
    "d[\"Newbie 1st class\"] = 1 #\n",
    "d[\"Junior Member\"] = 2 #\n",
    "d[\"Member\"] = 3#\n",
    "d[\"Senior Member\"] = 4 #\n",
    "d[\"Forum Veteran\"] = 5#1\n",
    "d[\"Forum Legend\"] = 6 #0\n",
    "d[\"Commercial paid-placement ads\"] = 7 # \n",
    "d[\"Banned\"] = -1 #\n",
    "d[\"null\"] = np.nan #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the special rolls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A singular modality',\n",
       " 'Join Date: Dec 2009',\n",
       " 'Moddy McModface',\n",
       " 'Moderately Amused',\n",
       " 'Moderato espressivo',\n",
       " 'NARU 25.3.2009',\n",
       " 'Only in moderation',\n",
       " 'RIP',\n",
       " 'Scammer until he proves otherwise',\n",
       " 'Staff at The Local',\n",
       " 'The Architect',\n",
       " 'Unbridled Mod',\n",
       " 'modified and reprogrammed',\n",
       " 'à la mod'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_rols=set()\n",
    "[[other_rols.add(user_exp) for user_exp in dfAuthors[key]['exp'] if user_exp not in list(d.keys())]for key in dfAuthors]\n",
    "other_rols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because they aren't so many of them. We will parse them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp values:  [  5.   0.   6.   2.   3.   1.   4.  nan  -1.   8.]\n"
     ]
    }
   ],
   "source": [
    "d[\"A singular modality\"] = 8 # Special rol\n",
    "d[\"Moderately Amused\"] = 8 # Special rol\n",
    "d[\"Only in moderation\"] = 8 # Special rol\n",
    "d[\"The Architect\"] = 8 # Special rol\n",
    "d[\"Unbridled Mod\"] = 8 # Special rol\n",
    "d[\"à la mod\"] = 8 #\n",
    "d[\"RIP\"] = 8 # Special rol\n",
    "d[\"Moddy McModface\"] = 8 # Special rol\n",
    "d[\"Moderato espressivo\"] = 8 # Special rol\n",
    "d[\"modified and reprogrammed\"] = 8 # Special rol\n",
    "d[\"Scammer until he proves otherwise\"] = 8 # Special rol\n",
    "for key in dfAuthors:\n",
    "    dfAuthors[key]['exp']=[d.get(item,item)  for item in dfAuthors[key]['exp']]\n",
    "print('Exp values: ',dfAuthors[key]['exp'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>6</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>152605</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>978</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  5.0  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45  0.0  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies reputation  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100          6   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5          0   \n",
       "\n",
       "       since     thanked                                      thread    user  \\\n",
       "0   Mar 2006  [901, 444]                 Switzerland Gigs \"Heads Up\"  Yokine   \n",
       "1   Nov 2016      [0, 0]  Small bars/places with acoustic livemusic?     JHC   \n",
       "\n",
       "  user_posts   views     topic  \n",
       "0       1233  152605  Concerts  \n",
       "1          3     978  Concerts  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuthors['ConcertsAuthors'].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's save the dataframes already parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in dfAuthors:\n",
    "    saveData(dfAuthors[key],(key))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
