{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4.element import Tag\n",
    "import pprint\n",
    "import traceback\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a variable with the URL to this tutorial\n",
    "url = 'http://www.englishforum.ch/forum.php'\n",
    "# Scrape the HTML at the url\n",
    "r = requests.get(url)\n",
    "# Turn the HTML into a Beautiful Soup object\n",
    "soup = BeautifulSoup(r.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business & entrepreneur': 'http://www.englishforum.ch/business-entrepreneur/',\n",
       " 'Commercial events': 'http://www.englishforum.ch/commercial-events/',\n",
       " 'Complaints corner': 'http://www.englishforum.ch/complaints-corner/',\n",
       " 'Concerts': 'http://www.englishforum.ch/concerts/',\n",
       " 'Daily life': 'http://www.englishforum.ch/daily-life/',\n",
       " 'Education': 'http://www.englishforum.ch/education/',\n",
       " 'Employment': 'http://www.englishforum.ch/employment/',\n",
       " 'Entertainment & dining': 'http://www.englishforum.ch/entertainment-dining/',\n",
       " 'Family matters/health': 'http://www.englishforum.ch/family-matters-health/',\n",
       " 'Finance/banking/taxation': 'http://www.englishforum.ch/finance-banking-taxation/',\n",
       " 'Food and drink': 'http://www.englishforum.ch/food-drink/',\n",
       " 'Housing in general': 'http://www.englishforum.ch/housing-general/',\n",
       " 'Insurance': 'http://www.englishforum.ch/insurance/',\n",
       " 'Introductions': 'http://www.englishforum.ch/introductions/',\n",
       " 'Language corner': 'http://www.englishforum.ch/language-corner/',\n",
       " 'Leaving Switzerland': 'http://www.englishforum.ch/leaving-switzerland/',\n",
       " 'Market Place': 'http://www.englishforum.ch/market-place/',\n",
       " 'Off-Topic': 'http://www.englishforum.ch/off-topic/',\n",
       " 'Other/general': 'http://www.englishforum.ch/other-general/',\n",
       " 'Permits/visas/government': 'http://www.englishforum.ch/permits-visas-government/',\n",
       " 'Pet corner': 'http://www.englishforum.ch/pet-corner/',\n",
       " 'Social events': 'http://www.englishforum.ch/social-events/',\n",
       " 'Sports / Fitness / Beauty / Wellness': 'http://www.englishforum.ch/sports-fitness-beauty-wellness/',\n",
       " 'Support': 'http://www.englishforum.ch/support/',\n",
       " 'Swiss news via The Local': 'http://www.englishforum.ch/swiss-news-via-local/',\n",
       " 'Swiss politics/news': 'http://www.englishforum.ch/swiss-politics-news/',\n",
       " 'TV/internet/telephone': 'http://www.englishforum.ch/tv-internet-telephone/',\n",
       " 'Transportation/driving': 'http://www.englishforum.ch/transportation-driving/',\n",
       " 'Travel/day trips/free time': 'http://www.englishforum.ch/travel-day-trips-free-time/'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create four variables to score the scraped data in\n",
    "dataframes={}\n",
    "for link in soup.find_all(\"strong\")[1:]:\n",
    "    for linkhref in soup.find_all(\"a\"):\n",
    "        if(link in linkhref and not linkhref['href'].endswith('.html') and link.contents[0] not in dataframes):\n",
    "            dataframes[link.contents[0]]=linkhref['href']\n",
    "dataframes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch the info from urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def comments(numPag,thread):\n",
    "    # Scrape the HTML at the url\n",
    "    response = requests.get(thread,headers={'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'})\n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    comments={}\n",
    "    inception={}\n",
    "    date=''\n",
    "    first=[]\n",
    "    user_and_rep=[]\n",
    "    for link in soup.find_all(\"div\",{\"align\":\"center\"}):\n",
    "        for link2 in link.find_all(\"div\",{\"align\":\"left\"}):\n",
    "            for link3 in link2.find_all(\"tr\"):\n",
    "                for link4 in link3.find_all(\"td\",{\"width\":\"99%\"}):\n",
    "                    for link5 in link4.find_all(\"div\"):\n",
    "                        if('id' in link5.attrs and 'posts' in link5['id']):\n",
    "                            link6=link5.find('table')\n",
    "#                             print(link6)\n",
    "\n",
    "                            try:\n",
    "                                link7=link6.find('td').find_all('div')\n",
    "                                if(len(link7)==0):\n",
    "                                    date='null'\n",
    "                                else:\n",
    "                                    date=link7[-1].contents[-1].strip(' \\n\\r\\t')\n",
    "                            except IndexError as  err:\n",
    "                                print(link6)\n",
    "                                print(thread)\n",
    "                                logging.error(traceback.format_exc())\n",
    "                                \n",
    "                            if(numPag==0 and 'null' not in date):\n",
    "                                for ind,link7 in enumerate(link6.find_all('div')):\n",
    "#                                 print(link7.contents[0])\n",
    "                                    if('href' not in link7 and len(link7.contents)>0):\n",
    "#                                         print('aaa',ind,type(link7.contents[0]),link7.contents[0])\n",
    "                                        if(type(link7.contents[0])==Tag):\n",
    "#                                         link7=link7.find('span')\n",
    "                                            if(len(link7.attrs)==0):\n",
    "#                                             print('aaa',ind,type(link7.contents[0]),link7.attrs,link7.contents[0])\n",
    "                                                    user_and_rep=str(link7.contents[0]).partition('alt=')[2]\n",
    "                                                    user_and_rep=user_and_rep.partition(user_and_rep[0]+' border')[0]\n",
    "                                                    if('has' in user_and_rep):\n",
    "                                                        user_and_rep=user_and_rep.partition(' has ')\n",
    "                                                    elif('is' in user_and_rep):\n",
    "                                                        user_and_rep=user_and_rep.partition(' is ')\n",
    "                                                    user_and_rep=[user_and_rep[0],user_and_rep[2]]\n",
    "                                               \n",
    "#                                         print(user_and_rep)\n",
    "                                        else:\n",
    "                                            stat=link7.contents[0].strip('\\n\\r\\t')\n",
    "#                                         if(stat!=' ' and ord(stat)!=160):\n",
    "                                            if(len(stat)>1 and ord(stat[0])!=160):\n",
    "#                                             print(link7)\n",
    "                                                first.append(stat)\n",
    "#                             if(len(user_and_rep)>0):\n",
    "                        if('id' in link5.attrs and link5['id'].startswith('post_message')):\n",
    "#                             print(link5.attrs,link5.contents)\n",
    "                            contents=''\n",
    "                            for content in link5.contents:\n",
    "                                if type(content) is not Tag:\n",
    "                                    contents+=' '+content\n",
    "#                                 comments[link5['id']]=content\n",
    "                                elif(str(content).startswith('<font')):\n",
    "                                    contents+=' '+re.sub(r'<.*?>', '', str(content))\n",
    "                                \n",
    "                            comments[link5['id']]=contents\n",
    "    retcomments=''\n",
    "    for ind,i in enumerate(sorted(comments)):\n",
    "#          print(comments[i])\n",
    "        if(numPag==0):\n",
    "#             print(user_and_rep,'len',len(first),first)\n",
    "            if(len(first)==6):\n",
    "                first.append(comments[i])\n",
    "            else:\n",
    "                first[-1]=comments[i]\n",
    "        retcomments+=comments[i]\n",
    "#     if(numPag==0):\n",
    "#         try:\n",
    "#             inception['user']=user_and_rep[0]\n",
    "#             inception['date']=date\n",
    "#             inception['reputation']=user_and_rep[1]\n",
    "#             inception['exp']=first[0]\n",
    "#             inception['since']=first[1]\n",
    "#             inception['location']=first[2]\n",
    "#             inception['posts']=first[3]\n",
    "#             inception['thanked']=first[4]\n",
    "#             inception['groaned']=first[5]\n",
    "#             inception['post']=first[6]\n",
    "#         except IndexError as err:\n",
    "#             print(len(first),first)\n",
    "#             print(user_and_rep,'len',len(first),first)\n",
    "#             print('IndexError:', err)\n",
    "        try:\n",
    "            if(numPag==0 and len(first)==7 and 'null' not in date):\n",
    "                inception['user']=user_and_rep[0][1:]\n",
    "                inception['date']=date\n",
    "                inception['reputation']=user_and_rep[1]\n",
    "                inception['exp']=first[0]\n",
    "                inception['since']=first[1]\n",
    "                inception['location']=first[2]\n",
    "                inception['posts']=first[3]\n",
    "                inception['groaned']=first[4]\n",
    "                inception['thanked']=first[5]\n",
    "                inception['post']=first[6]\n",
    "            elif(numPag==0):\n",
    "                inception['user']='guest'\n",
    "                inception['date']='null'\n",
    "                inception['reputation']='null'\n",
    "                inception['exp']='null'\n",
    "                inception['since']='null'\n",
    "                inception['location']='null'\n",
    "                inception['posts']='null'\n",
    "                inception['thanked']='null'\n",
    "                inception['groaned']='null'\n",
    "                inception['post']=first[-1]\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())\n",
    "            print(thread)\n",
    "            if(numPag==0):\n",
    "                inception['user']='guest'\n",
    "                inception['date']='null'\n",
    "                inception['reputation']='null'\n",
    "                inception['exp']='null'\n",
    "                inception['since']='null'\n",
    "                inception['location']='null'\n",
    "                inception['posts']='null'\n",
    "                inception['thanked']='null'\n",
    "                inception['groaned']='null'\n",
    "                inception['post']=first[-1]\n",
    "#             print(len(first),first)\n",
    "#             print(user_and_rep,'len',len(first),first)\n",
    "#             print('IndexError:', err)\n",
    "    return [retcomments,inception]\n",
    "\n",
    "def page(url,index):\n",
    "#     print(url,index)\n",
    "    # Scrape the HTML at the url\n",
    "    r = requests.get(url)    \n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    subtopic={}\n",
    "    for link in soup.find_all(\"table\",id=\"threadslist\"):\n",
    "#         print(link)\n",
    "        index_aux=index\n",
    "        dash=0\n",
    "        for replies in link.find_all(\"td\",class_=\"alt1\"):\n",
    "            if(replies.contents[0]!=' ' and type(replies.contents[0])!=Tag):\n",
    "                if(replies.contents[0]=='-'):\n",
    "                    dash+=1\n",
    "                subtopic[index_aux]=[]\n",
    "                subtopic[index_aux].append(replies.contents[0])\n",
    "# #                 print('rep',index_aux,replies.contents[0])\n",
    "\n",
    "                index_aux+=1\n",
    "    \n",
    "#         print('Replies found:',index_aux)\n",
    "        index_aux=index\n",
    "        insertdash=0\n",
    "        # \\xa0 Unicode --> ascii 160\n",
    "        for views in link.find_all(\"td\",class_=\"alt2\"):\n",
    "            if('align' in views.attrs and views.contents[0]!=' ' and ord(views.contents[0][0])!=160 and type(views.contents[0])!=Tag):\n",
    "                if(views.contents[0]=='-'):\n",
    "                    if(insertdash==0):\n",
    "                        insertdash=1\n",
    "                    else:\n",
    "                        insertdash=0\n",
    "                        subtopic[index_aux].append(views.contents[0])\n",
    "                        index_aux+=1\n",
    "                else:\n",
    "                    subtopic[index_aux].append(views.contents[0])\n",
    "                    index_aux+=1    \n",
    "#         print('Views found:',index_aux)\n",
    "        for thread in link.find_all(\"a\"):\n",
    "            if('id' in thread.attrs):\n",
    "#                 print('hrefs',index,link1.contents[0])\n",
    "                    subtopic[index].append(thread['href'])\n",
    "                    subtopic[index].append(thread.contents[0])\n",
    "                    index+=1\n",
    "        \n",
    "#         print('Threads found:',index)\n",
    "    return [subtopic,index]\n",
    "    \n",
    "    \n",
    "def findAllPages(rootHTML):\n",
    "    # Scrape the HTML at the url\n",
    "    r = requests.get(rootHTML)    \n",
    "    # Turn the HTML into a Beautiful Soup object\n",
    "    soup = BeautifulSoup(r.text, 'lxml')\n",
    "    lastUrl=''\n",
    "    pages=[]\n",
    "    pages.append(rootHTML)\n",
    "    for link in soup.find_all(\"body\"):\n",
    "        for link1 in link.find_all(\"a\"):\n",
    "            if('title' in link1.attrs and 'Last' in link1['title']):\n",
    "                lastUrl=link1['href']\n",
    "#                 print(link1['href'])\n",
    "                break\n",
    "    if(lastUrl==''):#no Last page link, we fetch last index page\n",
    "        links=set()\n",
    "        for link in soup.find_all(\"body\"):\n",
    "            for link1 in link.find_all(\"a\"):\n",
    "                if('title' in link1.attrs and 'Show results' in link1['title']):\n",
    "                    links.add(link1['href'])\n",
    "#                     print(link1)\n",
    "        if(links!=set() and rootHTML!=sorted(links)[-1]):\n",
    "            lastUrl=sorted(links)[-1]\n",
    "    if(lastUrl!=''):\n",
    "        if(rootHTML.endswith('.html')):\n",
    "            limit=re.findall(r'\\d+',lastUrl)[-1]\n",
    "            for i in range(2,int(limit)):\n",
    "                pages.append(re.sub(r'.html','',rootHTML)+\"-\"+str(i)+\".html\")\n",
    "        else:\n",
    "            limit=re.findall(r'\\d+',lastUrl)[0]\n",
    "            for i in range(2,int(limit)):\n",
    "                pages.append(rootHTML+\"index\"+str(i)+\".html\")\n",
    "        pages.append(lastUrl)\n",
    "        return pages\n",
    "    return pages\n",
    "    \n",
    "def createDF(url):\n",
    "#     print(url)\n",
    "    index=0\n",
    "    allsubtopics={}\n",
    "    nextPages=findAllPages(url)\n",
    "    for url in nextPages:\n",
    "#         print('urlllll',url)\n",
    "        result=page(url,index)\n",
    "        allsubtopics.update(result[0])\n",
    "        index=result[1]\n",
    "    #         print('fin',subtopic)\n",
    "    replies=[]\n",
    "    views=[]\n",
    "    hrefs=[]\n",
    "    threads=[]\n",
    "    first_posts=[]\n",
    "    print(\"For this tipic: %s there are %d subtopics\" %(url,len(allsubtopics)))\n",
    "    for value in allsubtopics.values():\n",
    "        replies.append(value[0])\n",
    "        views.append(value[1])\n",
    "        hrefs.append(value[2])\n",
    "        threads.append(value[3])\n",
    "    posts=[]\n",
    "    porcentaje=0\n",
    "    for indexhref,href in enumerate(hrefs):\n",
    "        nextPages=findAllPages(href)\n",
    "        threadPosts=[]\n",
    "        for numPag,pag in enumerate(nextPages):\n",
    "#             if(numPag==0):\n",
    "#                 print('pagina inicial del thread:'pag)\n",
    "#             threadPosts.append(comments(pag))\n",
    "            comments_call=comments(numPag,pag)\n",
    "            threadPosts.append(comments_call[0])\n",
    "            if(numPag==0):\n",
    "                first_posts.append(comments_call[1])\n",
    "        posts.append(''.join(threadPosts))\n",
    "        if((((indexhref*100)/len(hrefs)))>porcentaje):\n",
    "            print('Percentage of thread: ',int((indexhref*100)/len(hrefs)))\n",
    "            porcentaje=porcentaje+20;\n",
    "    date=[]\n",
    "    exp=[]\n",
    "    groaned=[]\n",
    "    location=[]\n",
    "    post=[]\n",
    "    user_posts=[]\n",
    "    reputation=[]\n",
    "    since=[]\n",
    "    thanked=[]\n",
    "    user=[]\n",
    "#     example of element first_posts\n",
    "#   {'date': '19.12.2014',\n",
    "#   'exp': 'Newbie',\n",
    "#   'groaned': 'Thanked 0 Times in 0 Posts',\n",
    "#   'location': 'Location: Basel',\n",
    "#   'post': \"Hi all. new to this site, i've been in basel for about 6 months now and was wondering about where and how i can buy e-cigarettes. i've heard they help people quit smoking and i read they are much cheaper too.\",\n",
    "#   'posts': 'Posts: 6',\n",
    "#   'reputation': 'has made some interesting contributions',\n",
    "#   'since': 'Join Date: Dec 2014',\n",
    "#   'thanked': 'Groaned at 1 Time in 1 Post',\n",
    "#   'user': 'WisePotato'}]\n",
    "    for index,stat in enumerate(first_posts):\n",
    "        if(len(stat)<9):\n",
    "            date.append('null')\n",
    "            exp.append('null')\n",
    "            groaned.append('null')\n",
    "            location.append('null')\n",
    "            post.append('null')\n",
    "            user_posts.append('null')\n",
    "            reputation.append('null')\n",
    "            since.append('null')\n",
    "            thanked.append('null')\n",
    "            user.append('null')\n",
    "#             print('print stats:',stat)\n",
    "#             print('print index:',index)\n",
    "#             print('hrefs',len(hrefs),'firsts',len(first_posts))\n",
    "#             print(index,hrefs[index])\n",
    "        else:\n",
    "            date.append(stat['date'])\n",
    "            exp.append(stat['exp'])\n",
    "            groaned.append(stat['groaned'])\n",
    "            location.append(stat['location'])\n",
    "            post.append(stat['post'])\n",
    "            user_posts.append(stat['posts'])\n",
    "            reputation.append(stat['reputation'])\n",
    "            since.append(stat['since'])\n",
    "            thanked.append(stat['thanked'])\n",
    "            user.append(stat['user'])\n",
    "#     df = pd.DataFrame({'replies': replies, 'views': views, 'hrefs': hrefs, 'threads' : threads, 'posts': posts})\n",
    "#     firstDF=pd.DataFrame({'user':user,'thread':threads,'date':date,'exp':exp,'groaned':groaned,'location':location,'post':post,'user_posts':user_posts,'reputation':reputation,'since':since,'thanked':thanked})\n",
    "    joindf=pd.DataFrame({'thread':threads,'user':user,'views': views,'replies': replies,'location':location,'date':date,'post':posts,'user_posts':user_posts,'since':since,'exp':exp,'thanked':thanked,'groaned':groaned,'reputation':reputation})\n",
    "    return joindf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data into csv folder and remove dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saveData(dataframe,i):\n",
    "    dataframe.to_csv(\"csv/\"+i.replace(\"/\",\"\")+\".csv\", sep='\\t', encoding='utf-8',)\n",
    "    del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes we'd like to fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Business & entrepreneur http://www.englishforum.ch/business-entrepreneur/\n",
      "1 Commercial events http://www.englishforum.ch/commercial-events/\n",
      "2 Complaints corner http://www.englishforum.ch/complaints-corner/\n",
      "3 Concerts http://www.englishforum.ch/concerts/\n",
      "4 Daily life http://www.englishforum.ch/daily-life/\n",
      "5 Education http://www.englishforum.ch/education/\n",
      "6 Employment http://www.englishforum.ch/employment/\n",
      "7 Entertainment & dining http://www.englishforum.ch/entertainment-dining/\n",
      "8 Family matters/health http://www.englishforum.ch/family-matters-health/\n",
      "9 Finance/banking/taxation http://www.englishforum.ch/finance-banking-taxation/\n",
      "10 Food and drink http://www.englishforum.ch/food-drink/\n",
      "11 Housing in general http://www.englishforum.ch/housing-general/\n",
      "12 Insurance http://www.englishforum.ch/insurance/\n",
      "13 Introductions http://www.englishforum.ch/introductions/\n",
      "14 Language corner http://www.englishforum.ch/language-corner/\n",
      "15 Leaving Switzerland http://www.englishforum.ch/leaving-switzerland/\n",
      "16 Market Place http://www.englishforum.ch/market-place/\n",
      "17 Off-Topic http://www.englishforum.ch/off-topic/\n",
      "18 Other/general http://www.englishforum.ch/other-general/\n",
      "19 Permits/visas/government http://www.englishforum.ch/permits-visas-government/\n",
      "20 Pet corner http://www.englishforum.ch/pet-corner/\n",
      "21 Social events http://www.englishforum.ch/social-events/\n",
      "22 Sports / Fitness / Beauty / Wellness http://www.englishforum.ch/sports-fitness-beauty-wellness/\n",
      "23 Support http://www.englishforum.ch/support/\n",
      "24 Swiss news via The Local http://www.englishforum.ch/swiss-news-via-local/\n",
      "25 Swiss politics/news http://www.englishforum.ch/swiss-politics-news/\n",
      "26 TV/internet/telephone http://www.englishforum.ch/tv-internet-telephone/\n",
      "27 Transportation/driving http://www.englishforum.ch/transportation-driving/\n",
      "28 Travel/day trips/free time http://www.englishforum.ch/travel-day-trips-free-time/\n"
     ]
    }
   ],
   "source": [
    "# for i in dataframes:\n",
    "for index,i in enumerate(sorted(dataframes)):\n",
    "    print(index,i,dataframes[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In order to read from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readData(filename):\n",
    "    if( not filename.endswith('.csv')):\n",
    "        filename+='.csv'\n",
    "    df = pd.read_csv('csv/'+filename, header=0,sep='\\t',index_col=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV files we have got so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Business & entrepreneur.csv\n",
      "1 Business & entrepreneurAuthors.csv\n",
      "2 Commercial events.csv\n",
      "3 Commercial eventsAuthors.csv\n",
      "4 Complaints corner.csv\n",
      "5 Complaints cornerAuthors.csv\n",
      "6 Concerts.csv\n",
      "7 ConcertsAuthors.csv\n",
      "8 Daily life.csv\n",
      "9 Daily lifeAuthors.csv\n",
      "10 Education.csv\n",
      "11 EducationAuthors.csv\n",
      "12 Employment.csv\n",
      "13 EmploymentAuthors.csv\n",
      "14 Entertainment & dining.csv\n",
      "15 Entertainment & diningAuthors.csv\n",
      "16 Family mattershealth.csv\n",
      "17 Family mattershealthAuthors.csv\n",
      "18 Financebankingtaxation.csv\n",
      "19 FinancebankingtaxationAuthors.csv\n",
      "20 Food and drink.csv\n",
      "21 Food and drinkAuthors.csv\n",
      "22 Insurance.csv\n",
      "23 InsuranceAuthors.csv\n",
      "24 Introductions.csv\n",
      "25 IntroductionsAuthors.csv\n",
      "26 Language corner.csv\n",
      "27 Language cornerAuthors.csv\n",
      "28 Leaving Switzerland.csv\n",
      "29 Leaving SwitzerlandAuthors.csv\n",
      "30 Othergeneral.csv\n",
      "31 OthergeneralAuthors.csv\n",
      "32 Permitsvisasgovernment.csv\n",
      "33 PermitsvisasgovernmentAuthors.csv\n",
      "34 Pet corner.csv\n",
      "35 Pet cornerAuthors.csv\n",
      "36 Social events.csv\n",
      "37 Social eventsAuthors.csv\n",
      "38 Sports  Fitness  Beauty  Wellness.csv\n",
      "39 Sports  Fitness  Beauty  WellnessAuthors.csv\n",
      "40 Swiss news via The Local.csv\n",
      "41 Swiss news via The LocalAuthors.csv\n",
      "42 Swiss politicsnews.csv\n",
      "43 Swiss politicsnewsAuthors.csv\n",
      "44 TVinternettelephone.csv\n",
      "45 TVinternettelephoneAuthors.csv\n",
      "46 Transportationdriving.csv\n",
      "47 TransportationdrivingAuthors.csv\n",
      "48 Travelday tripsfree time.csv\n",
      "49 Travelday tripsfree timeAuthors.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for index,i in enumerate(sorted(os.listdir(\"csv/\"))):\n",
    "    print(index,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In case we'd like to update the files, let's declare the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_enterpreteur=None\n",
    "complaints_corner=None\n",
    "concerts=None\n",
    "daily_life=None\n",
    "employment=None\n",
    "entertainment_dining=None\n",
    "family_matters_health=None\n",
    "finance_banking_taxation=None\n",
    "food_drink=None\n",
    "housing=None\n",
    "insurance=None\n",
    "introductions=None\n",
    "language_corner=None\n",
    "leaving_switzerland=None\n",
    "market_place=None\n",
    "off_topic=None\n",
    "other_general=None\n",
    "permits_visas_gov=None\n",
    "pet_corner=None\n",
    "sports_wellness=None\n",
    "support=None\n",
    "swiss_politics_news=None\n",
    "transportation_driving=None\n",
    "travel_free_time=None\n",
    "tv_internet_telephone=None\n",
    "# NON FETCHED BUT YET TO COME\n",
    "commercial_events=None\n",
    "education=None\n",
    "social_events=None\n",
    "swiss_news=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Let's download them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the data from the forum can take around 1-2 days and some times we just want to update part of the data. \n",
    "The cell below allow us to choose which topics (of the forum) we would like to download. \n",
    "By commenting lines you will select he topics you want to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 http://www.englishforum.ch/business-entrepreneur/\n",
      "1 http://www.englishforum.ch/commercial-events/\n",
      "2 http://www.englishforum.ch/complaints-corner/\n",
      "3 http://www.englishforum.ch/concerts/\n",
      "For this tipic: http://www.englishforum.ch/concerts/index29.html there are 848 subtopics\n",
      "Percentage of thread:  0\n",
      "Percentage of thread:  20\n",
      "Percentage of thread:  40\n",
      "Percentage of thread:  60\n",
      "Percentage of thread:  80\n",
      "4 http://www.englishforum.ch/daily-life/\n",
      "5 http://www.englishforum.ch/education/\n",
      "6 http://www.englishforum.ch/employment/\n",
      "7 http://www.englishforum.ch/entertainment-dining/\n",
      "8 http://www.englishforum.ch/family-matters-health/\n",
      "9 http://www.englishforum.ch/finance-banking-taxation/\n",
      "10 http://www.englishforum.ch/food-drink/\n",
      "11 http://www.englishforum.ch/housing-general/\n",
      "12 http://www.englishforum.ch/insurance/\n",
      "13 http://www.englishforum.ch/introductions/\n",
      "14 http://www.englishforum.ch/language-corner/\n",
      "15 http://www.englishforum.ch/leaving-switzerland/\n",
      "16 http://www.englishforum.ch/market-place/\n",
      "17 http://www.englishforum.ch/off-topic/\n",
      "18 http://www.englishforum.ch/other-general/\n",
      "19 http://www.englishforum.ch/permits-visas-government/\n",
      "20 http://www.englishforum.ch/pet-corner/\n",
      "21 http://www.englishforum.ch/social-events/\n",
      "22 http://www.englishforum.ch/sports-fitness-beauty-wellness/\n",
      "23 http://www.englishforum.ch/support/\n",
      "24 http://www.englishforum.ch/swiss-news-via-local/\n",
      "25 http://www.englishforum.ch/swiss-politics-news/\n",
      "26 http://www.englishforum.ch/tv-internet-telephone/\n",
      "27 http://www.englishforum.ch/transportation-driving/\n",
      "28 http://www.englishforum.ch/travel-day-trips-free-time/\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(sorted(dataframes)):\n",
    "    print(index, dataframes[i])\n",
    "#     df=createDF(dataframes[i][0])\n",
    "#     saveData(df)\n",
    "    if index==0: skip=1          #  business_enterpreteur\n",
    "    elif index==1: skip=1        #  commercial-events\n",
    "    elif index==2: skip=1        #  complaints-corner\n",
    "#     elif index==3: skip=1        #  concerts \n",
    "    elif index==4: skip=1        #  daily-life\n",
    "    elif index==5: skip=1        #  education\n",
    "    elif index==6: skip=1        #  employment\n",
    "    elif index==7: skip=1        #  entertainment-dining\n",
    "    elif index==8: skip=1        #  family-matters-health\n",
    "    elif index==9: skip=1        #  finance-banking-taxation\n",
    "    elif index==10: skip=1       #  food-drink\n",
    "    elif index==11: skip=0       #  housing-general/\n",
    "    elif index==12: skip=1       #  insurance\n",
    "    elif index==13: skip=1       #  introductions\n",
    "    elif index==14: skip=1       #  language_corner\n",
    "    elif index==15: skip=1       #  leaving_switzerland\n",
    "    elif index==16: skip=0       #  market_place\n",
    "    elif index==17: skip=0       #  off_topic\n",
    "    elif index==18: skip=1       #  other_general\n",
    "    elif index==19: skip=1       #  permits_visas_gov\n",
    "    elif index==20: skip=1       #  pet_corner\n",
    "    elif index==21: skip=1       #  social_events\n",
    "    elif index==22: skip=1       #  sports_wellness\n",
    "    elif index==23: skip=0       #  support\n",
    "    elif index==24: skip=1       #  swiss_news\n",
    "    elif index==25: skip=1       #  swiss_politics_news\n",
    "    elif index==26: skip=1       #  tv_internet_telephone\n",
    "    elif index==27: skip=1       #  transportation_driving\n",
    "    elif index==28: skip=1\n",
    "    else:     \n",
    "        try:\n",
    "            createDFRet=createDF(dataframes[i])\n",
    "            createDFRet['topic']=i\n",
    "            saveData(createDFRet,(i+\"Authors\"))\n",
    "        except Exception as e:\n",
    "            logging.error(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all data at once, parse it and save it again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded our data and save it to localstorage, we need to be transform it from ”dirty” to clean, as we saw during the course.\n",
    "We will remove some incoherent information, treat null and parse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['csv/Business & entrepreneurAuthors.csv', 'csv/ConcertsAuthors.csv', 'csv/EducationAuthors.csv', 'csv/PermitsvisasgovernmentAuthors.csv', 'csv/Commercial eventsAuthors.csv', 'csv/Travelday tripsfree timeAuthors.csv', 'csv/Daily lifeAuthors.csv', 'csv/EmploymentAuthors.csv', 'csv/TransportationdrivingAuthors.csv', 'csv/Language cornerAuthors.csv', 'csv/Swiss news via The LocalAuthors.csv', 'csv/TVinternettelephoneAuthors.csv', 'csv/OthergeneralAuthors.csv', 'csv/Swiss politicsnewsAuthors.csv', 'csv/IntroductionsAuthors.csv', 'csv/Social eventsAuthors.csv', 'csv/Food and drinkAuthors.csv', 'csv/Leaving SwitzerlandAuthors.csv', 'csv/FinancebankingtaxationAuthors.csv', 'csv/Family mattershealthAuthors.csv', 'csv/InsuranceAuthors.csv', 'csv/Entertainment & diningAuthors.csv', 'csv/Complaints cornerAuthors.csv', 'csv/Pet cornerAuthors.csv', 'csv/Sports  Fitness  Beauty  WellnessAuthors.csv'] dict_keys(['ConcertsAuthors', 'Complaints cornerAuthors', 'InsuranceAuthors', 'Sports  Fitness  Beauty  WellnessAuthors', 'Swiss news via The LocalAuthors', 'TransportationdrivingAuthors', 'Leaving SwitzerlandAuthors', 'Swiss politicsnewsAuthors', 'FinancebankingtaxationAuthors', 'Family mattershealthAuthors', 'Daily lifeAuthors', 'Business & entrepreneurAuthors', 'TVinternettelephoneAuthors', 'Social eventsAuthors', 'Food and drinkAuthors', 'Language cornerAuthors', 'IntroductionsAuthors', 'EducationAuthors', 'Travelday tripsfree timeAuthors', 'Pet cornerAuthors', 'Entertainment & diningAuthors', 'OthergeneralAuthors', 'EmploymentAuthors', 'PermitsvisasgovernmentAuthors', 'Commercial eventsAuthors'])\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "dfAuthors={}\n",
    "filenames = [fn for fn in glob.glob(\"csv/*.csv\") \n",
    "         if os.path.basename(fn).endswith('Authors.csv')]\n",
    "for index,filename in enumerate(filenames):\n",
    "    df = pd.read_csv(filename, header=0,sep='\\t',index_col=0)\n",
    "    dfAuthors[re.sub(r'.csv','',os.path.basename(filename))]=df\n",
    "print(filenames,dfAuthors.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how our data initially looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>Groaned at 1 Time in 1 Post</td>\n",
       "      <td>Location: Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1,100</td>\n",
       "      <td>a reputation beyond repute</td>\n",
       "      <td>Join Date: Mar 2006</td>\n",
       "      <td>Thanked 901 Times in 444 Posts</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>Posts: 1,233</td>\n",
       "      <td>151,570</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>Groaned at 0 Times in 0 Posts</td>\n",
       "      <td>Location: Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Join Date: Nov 2016</td>\n",
       "      <td>Thanked 0 Times in 0 Posts</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>Posts: 3</td>\n",
       "      <td>931</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28.11.2015, 22:48</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>Groaned at 0 Times in 0 Posts</td>\n",
       "      <td>Location: Spain</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tHello there!   \\r\\nI am a...</td>\n",
       "      <td>16</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Join Date: Jul 2015</td>\n",
       "      <td>Thanked 0 Times in 0 Posts</td>\n",
       "      <td>Jazz clubs Zurich?</td>\n",
       "      <td>aromeroa</td>\n",
       "      <td>Posts: 6</td>\n",
       "      <td>3,849</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp                        groaned  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran    Groaned at 1 Time in 1 Post   \n",
       "1  19.11.2016, 19:45         Newbie  Groaned at 0 Times in 0 Posts   \n",
       "2  28.11.2015, 22:48         Newbie  Groaned at 0 Times in 0 Posts   \n",
       "\n",
       "                     location  \\\n",
       "0           Location: Perthia   \n",
       "1  Location: Lenzburg, Aargau   \n",
       "2             Location: Spain   \n",
       "\n",
       "                                                post replies  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...   1,100   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5   \n",
       "2   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tHello there!   \\r\\nI am a...      16   \n",
       "\n",
       "                            reputation                since  \\\n",
       "0           a reputation beyond repute  Join Date: Mar 2006   \n",
       "1  no particular reputation at present  Join Date: Nov 2016   \n",
       "2  no particular reputation at present  Join Date: Jul 2015   \n",
       "\n",
       "                          thanked                                      thread  \\\n",
       "0  Thanked 901 Times in 444 Posts                 Switzerland Gigs \"Heads Up\"   \n",
       "1      Thanked 0 Times in 0 Posts  Small bars/places with acoustic livemusic?   \n",
       "2      Thanked 0 Times in 0 Posts                          Jazz clubs Zurich?   \n",
       "\n",
       "       user    user_posts    views     topic  \n",
       "0    Yokine  Posts: 1,233  151,570  Concerts  \n",
       "1       JHC      Posts: 3      931  Concerts  \n",
       "2  aromeroa      Posts: 6    3,849  Concerts  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuthors['ConcertsAuthors'].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parsing\n",
    "All cells are string type. We would like to convert all string numbers to integers (or floats) and for that we need to remove the comas.\n",
    "We also want to transform dates represented in the same way (column \"date\" can have date types and text as \"today\" or \"yesterday\")\n",
    "Finally, there is useless text mixed with more important data like in the column \"location\", in which we can find the word \"location:\" always repeted per cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>a reputation beyond repute</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>151570</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>no particular reputation at present</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45         Newbie  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5   \n",
       "\n",
       "                            reputation      since     thanked  \\\n",
       "0           a reputation beyond repute   Mar 2006  [901, 444]   \n",
       "1  no particular reputation at present   Nov 2016      [0, 0]   \n",
       "\n",
       "                                       thread    user user_posts   views  \\\n",
       "0                 Switzerland Gigs \"Heads Up\"  Yokine       1233  151570   \n",
       "1  Small bars/places with acoustic livemusic?     JHC          3     931   \n",
       "\n",
       "      topic  \n",
       "0  Concerts  \n",
       "1  Concerts  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "for key in dfAuthors:\n",
    "    # # Casting views from str to int (- to 0 because is a moved)\n",
    "    today=datetime.strptime(time.ctime(os.path.getctime('csv/'+key+'.csv')),'%a %b %d %H:%M:%S %Y')\n",
    "    yesterday=today- timedelta(days=1)\n",
    "    tdy=\"%d.%d.%d\" %(today.day,today.month,today.year)\n",
    "    ystr=\"%d.%d.%d\" %(yesterday.day,yesterday.month,yesterday.year)\n",
    "    \n",
    "    \n",
    "    dfAuthors[key]['views']=dfAuthors[key]['views'].apply(lambda x: str(x).replace(',',''))\n",
    "    dfAuthors[key]['replies']=dfAuthors[key]['replies'].apply(lambda x: str(x).replace(',',''))\n",
    "    #     dfAuthors[key].user_posts=dfAuthors[key].apply(lambda x: x[9].replace('Posts: ','').replace(',','').replace('-','0') ,axis=1)\n",
    "    #     [print(key) for x in dfAuthors[key]['since'] if 'Location: Lugano' in x]\n",
    "    #     dfAuthors[key]['views']=dfAuthors[key]['views'].apply(lambda x: int(x.replace(',','').replace('-','0')))\n",
    "    #   dfAuthors[key]['replies']=dfAuthors[key]['replies'].apply(lambda x: int(str(x).replace(',','').replace('-','0')))\n",
    "    dfAuthors[key]['user_posts']=dfAuthors[key]['user_posts'].apply(lambda x: ''.join(re.findall(r'\\d+',x)))\n",
    "    dfAuthors[key]['user']=dfAuthors[key]['user'].apply(lambda x: str(x).replace(str(x)[0],'') if((str(x)[0])=='\"') else str(x))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: str(x))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: x.replace('Yesterday',ystr))\n",
    "    dfAuthors[key]['date']=dfAuthors[key]['date'].apply(lambda x: x.replace('Today',tdy))\n",
    "    #     dfAuthors[key]['date']=[datetime.strptime(x, '%d.%m.%Y, %H:%M')for x in dfAuthors[key]['date'] if (x!='null')]\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: str(x))\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: x.replace('Join Date:',''))\n",
    "    dfAuthors[key]['since']=dfAuthors[key]['since'].apply(lambda x: x.replace('null',(\" Jun 0001\")))\n",
    "    #     dfAuthors[key]['since']=[datetime.strptime(x, ' %b %Y')for x in dfAuthors[key]['since']]\n",
    "    dfAuthors[key]['location']=dfAuthors[key]['location'].apply(lambda x: x.replace('Location: ',''))\n",
    "    dfAuthors[key].head()\n",
    "    # Thanked 418 Times in 115 \n",
    "    # Groaned at 3 Times in 3 Posts\n",
    "    dfAuthors[key]['groaned']=dfAuthors[key]['groaned'].apply(lambda x: re.findall(r'\\d+',x))\n",
    "    dfAuthors[key]['thanked']=dfAuthors[key]['thanked'].apply(lambda x: re.findall(r'\\d+',x))\n",
    "    # print(filenames)\n",
    "dfAuthors[key].head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reputation transformation. Basic transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reputation values:  ['a reputation beyond repute' 'no particular reputation at present'\n",
      " 'slipped a little' 'considered knowledgeable'\n",
      " 'made some interesting contributions' 'earned some respect' 'null'\n",
      " 'become a little unpopular' 'an excellent reputation'\n",
      " 'considered a nuisance' 'annoyed a few people around here'\n",
      " 'earned the respect of many' 'm' 'considered unworthy']\n"
     ]
    }
   ],
   "source": [
    "print('Reputation values: ',dfAuthors['ConcertsAuthors']['reputation'].unique())\n",
    "d = {}\n",
    "d[\"a reputation beyond repute\"] = 6 # \n",
    "d[\"an excellent reputation\"] = 5 # \n",
    "d[\"considered knowledgeable\"] = 4 #\n",
    "d[\"earned the respect of many\"] = 3 #\n",
    "d[\"earned some respect\"] = 2#\n",
    "d[\"made some interesting contributions\"] = 1 #\n",
    "d[\"no particular reputation at present\"] = 0#1\n",
    "d[\"slipped a little\"] = -1 #0\n",
    "d[\"become a little unpopular\"] = -2 #\n",
    "d[\"annoyed a few people around here\"] = -3 #\n",
    "d[\"considered a nuisance\"] = -4 #\n",
    "d[\"considered unworthy\"] = -5 #\n",
    "d[\"null\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'m'}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques=set()\n",
    "[[uniques.add(user_exp) for user_exp in dfAuthors[key]['reputation'] if user_exp not in list(d.keys())]for key in dfAuthors]\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>Forum Veteran</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>6</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>151570</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>Newbie</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date            exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  Forum Veteran  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45         Newbie  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies reputation  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100          6   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5          0   \n",
       "\n",
       "       since     thanked                                      thread    user  \\\n",
       "0   Mar 2006  [901, 444]                 Switzerland Gigs \"Heads Up\"  Yokine   \n",
       "1   Nov 2016      [0, 0]  Small bars/places with acoustic livemusic?     JHC   \n",
       "\n",
       "  user_posts   views     topic  \n",
       "0       1233  151570  Concerts  \n",
       "1          3     931  Concerts  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for key in dfAuthors:\n",
    "    dfAuthors[key]['reputation']=[d.get(item,item)  for item in dfAuthors[key]['reputation']]\n",
    "dfAuthors[key].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reputation values:  ['Forum Veteran' 'Newbie' 'Forum Legend' 'Junior Member' 'Member'\n",
      " 'Newbie 1st class' 'Senior Member' 'null' 'Banned'\n",
      " 'modified and reprogrammed' 'RIP' 'Moderato espressivo']\n"
     ]
    }
   ],
   "source": [
    "print('Reputation values: ',dfAuthors[key]['exp'].unique())\n",
    "# Basic exp\n",
    "d = {}\n",
    "d[\"Newbie\"] = 0 # \n",
    "d[\"Newbie 1st class\"] = 1 #\n",
    "d[\"Junior Member\"] = 2 #\n",
    "d[\"Member\"] = 3#\n",
    "d[\"Senior Member\"] = 4 #\n",
    "d[\"Forum Veteran\"] = 5#1\n",
    "d[\"Forum Legend\"] = 6 #0\n",
    "d[\"Commercial paid-placement ads\"] = 7 # \n",
    "d[\"Banned\"] = -1 #\n",
    "d[\"null\"] = np.nan #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some special rols:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Moderato espressivo', 'RIP', 'modified and reprogrammed'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_rols=set()\n",
    "[[other_rols.add(user_exp) for user_exp in dfAuthors[key]['exp'] if user_exp not in list(d.keys())]for key in dfAuthors]\n",
    "other_rols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because they aren't so many of them. We will parse them manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp values:  [  5.   0.   6.   2.   3.   1.   4.  nan  -1.   8.]\n"
     ]
    }
   ],
   "source": [
    "# dfAuthors['EducationAuthors'].head()\n",
    "d[\"A singular modality\"] = 8 # Special rol\n",
    "d[\"Moderately Amused\"] = 8 # Special rol\n",
    "d[\"Only in moderation\"] = 8 # Special rol\n",
    "d[\"The Architect\"] = 8 # Special rol\n",
    "d[\"Unbridled Mod\"] = 8 # Special rol\n",
    "d[\"à la mod\"] = 8 #\n",
    "d[\"RIP\"] = 8 # Special rol\n",
    "d[\"Moddy McModface\"] = 8 # Special rol\n",
    "d[\"Moderato espressivo\"] = 8 # Special rol\n",
    "d[\"modified and reprogrammed\"] = 8 #\n",
    "\n",
    "# temp=map(d.get, dfAuthors['EducationAuthors']['reputation'], dfAuthors['EducationAuthors']['reputation'])\n",
    "for key in dfAuthors:\n",
    "    dfAuthors[key]['exp']=[d.get(item,item)  for item in dfAuthors[key]['exp']]\n",
    "# dfAuthors['Complaints cornerAuthors'][(dfAuthors['Complaints cornerAuthors']['exp']=='Join Date: Dec 2009')]\n",
    "print('Exp values: ',dfAuthors[key]['exp'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>exp</th>\n",
       "      <th>groaned</th>\n",
       "      <th>location</th>\n",
       "      <th>post</th>\n",
       "      <th>replies</th>\n",
       "      <th>reputation</th>\n",
       "      <th>since</th>\n",
       "      <th>thanked</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>views</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06.05.2009, 16:20</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>Perthia</td>\n",
       "      <td>Mod Insert:  Please  . Can't be bothered si...</td>\n",
       "      <td>1100</td>\n",
       "      <td>6</td>\n",
       "      <td>Mar 2006</td>\n",
       "      <td>[901, 444]</td>\n",
       "      <td>Switzerland Gigs \"Heads Up\"</td>\n",
       "      <td>Yokine</td>\n",
       "      <td>1233</td>\n",
       "      <td>151570</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.11.2016, 19:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Lenzburg, Aargau</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Nov 2016</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Small bars/places with acoustic livemusic?</td>\n",
       "      <td>JHC</td>\n",
       "      <td>3</td>\n",
       "      <td>931</td>\n",
       "      <td>Concerts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date  exp groaned          location  \\\n",
       "0  06.05.2009, 16:20  5.0  [1, 1]           Perthia   \n",
       "1  19.11.2016, 19:45  0.0  [0, 0]  Lenzburg, Aargau   \n",
       "\n",
       "                                                post replies reputation  \\\n",
       "0     Mod Insert:  Please  . Can't be bothered si...    1100          6   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI am living in Kanton Aar...       5          0   \n",
       "\n",
       "       since     thanked                                      thread    user  \\\n",
       "0   Mar 2006  [901, 444]                 Switzerland Gigs \"Heads Up\"  Yokine   \n",
       "1   Nov 2016      [0, 0]  Small bars/places with acoustic livemusic?     JHC   \n",
       "\n",
       "  user_posts   views     topic  \n",
       "0       1233  151570  Concerts  \n",
       "1          3     931  Concerts  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuthors['ConcertsAuthors'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>thread</th>\n",
       "      <th>user</th>\n",
       "      <th>views</th>\n",
       "      <th>replies</th>\n",
       "      <th>location</th>\n",
       "      <th>date</th>\n",
       "      <th>post</th>\n",
       "      <th>user_posts</th>\n",
       "      <th>since</th>\n",
       "      <th>exp</th>\n",
       "      <th>thanked</th>\n",
       "      <th>groaned</th>\n",
       "      <th>reputation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business &amp; entrepreneur</td>\n",
       "      <td>Posting in this area - guidelines - rules - re...</td>\n",
       "      <td>mark</td>\n",
       "      <td>17624</td>\n",
       "      <td>0</td>\n",
       "      <td>Zollikon, Switzerland</td>\n",
       "      <td>11.08.2006, 15:44</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tThis area is intended as ...</td>\n",
       "      <td>3070.0</td>\n",
       "      <td>May 2005</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['3', '3']</td>\n",
       "      <td>['418', '115']</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Business &amp; entrepreneur</td>\n",
       "      <td>Questions about liability and invoicing of Fre...</td>\n",
       "      <td>Nano</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>Solothurn</td>\n",
       "      <td>18.1.2017, 23:08</td>\n",
       "      <td>\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI work though my own GmbH...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Jan 2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['0', '0']</td>\n",
       "      <td>['0', '0']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     topic                                             thread  \\\n",
       "0  Business & entrepreneur  Posting in this area - guidelines - rules - re...   \n",
       "1  Business & entrepreneur  Questions about liability and invoicing of Fre...   \n",
       "\n",
       "   user  views  replies               location               date  \\\n",
       "0  mark  17624        0  Zollikon, Switzerland  11.08.2006, 15:44   \n",
       "1  Nano    139        2              Solothurn   18.1.2017, 23:08   \n",
       "\n",
       "                                                post  user_posts      since  \\\n",
       "0   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tThis area is intended as ...      3070.0   May 2005   \n",
       "1   \\r\\n\\t\\t\\t\\r\\n\\t\\t\\tI work though my own GmbH...         2.0   Jan 2017   \n",
       "\n",
       "   exp     thanked         groaned reputation  \n",
       "0  8.0  ['3', '3']  ['418', '115']          6  \n",
       "1  0.0  ['0', '0']      ['0', '0']          0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfAuthors['Business & entrepreneurAuthors'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in dfAuthors:\n",
    "    saveData(dfAuthors[key],(key))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
